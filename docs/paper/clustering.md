# 常用聚类算法

## AP聚类

### AP聚类的基本思想

AP(Affinity Propagation)通常被翻译为近邻传播算法或者亲和力传播算法，它是基于数据点间的"信息传递"的一种聚类算法。AP算法的基本思想是将全部数据点都当作潜在的聚类中心(称之为exemplar)，然后数据点两两之间连线构成一个网络(相似度矩阵)，共有两种消息在各节点间传递，分别是吸引度(responsibility)和归属度(availability) 。AP算法通过迭代过程不断更新每一个点的吸引度和归属度值，直到产生m个高质量的Exemplar（类似于质心），同时将其余的数据点分配到相应的聚类中。与k-均值算法或k中心点算法不同，AP算法不需要在运行算法之前确定聚类的个数。AP算法寻找的"examplars"是数据集合中实际存在的点，作为每类的代表。

### AP聚类的相关概念

Exemplar（聚类中心）：类似于K-Means中的质心，AP算法不需要事先指定聚类数目，相反它将所有的数据点都作为潜在的聚类中心。

Similarity（相似度）：数据点$i$和点$j$的相似度记为$s(i,j)$，是指点$j$作为点$i$的聚类中心的相似度。一般使用欧氏距离来计算，一般点与点的相似度值全部取为负值；因此，相似度值越大说明点与点的距离越近，便于后面的比较计算。

Preference（参考度）：数据点$i$的参考度称为$p(i)$或$s(i,i)$，是指点$i$作为聚类中心的参考度，以S矩阵的对角线上的数值$s(k,k)$作为$k$点能否成为聚类中心的评判标准，这意味着该值越大，这个点成为聚类中心的可能性也就越大。一般取s相似度值的中值(Scikit-learn中默认为中位数)。聚类的数量受到参考度p的影响,如果认为每个数据点都有可能作为聚类中心,那么p就应取相同的值。如果取输入的相似度的均值作为p的值,得到聚类数量是中等的。如果取最小值,得到类数较少的聚类。

Responsibility（吸引度）：$r(i,k)$用来描述点$k$适合作为数据点$i$的聚类中心的程度。

Availability（归属度）：$a(i,k)$用来描述点$i$选择点$k$作为其聚类中心的适合程度。

Damping factor(阻尼系数)：主要是起收敛作用。

在实际计算应用中，最重要的两个参数（也是需要手动指定）是Preference和Damping factor。前者定了聚类数量的多少，值越大聚类数量越多；后者控制算法收敛效果。

### AP算法全文

基于相似性度量的数据聚类是科学数据分析和工程系统中的一个关键步骤。一种常见的方法是使用数据来学习一组中心，这样数据点与其最近中心之间的平方误差之和就很小。当从实际数据点中选择中心时，它们被称为“样本（exemplars）”。流行的k-中心聚类技术从随机选择的样本的初始集合开始，并迭代地细化该集合以减少平方误差之和。k中心聚类对样本的初始选择非常敏感，因此通常会使用不同的初始化多次重新运行，以试图找到一个好的解决方案。然而，只有当集群的数量很小并且至少有一个随机初始化接近一个好的解决方案时，这种方法才能很好地工作。我们采用了一种完全不同的方法，并引入了一种同时考虑所有数据点作为潜在示例的方法。
通过将每个数据点看作网络中的一个节点，我们设计了一种沿着网络边缘递归传输实值消息的方法，直到出现一组好的示例和相应的簇。如后文所述，根据搜索适当选择的能量函数的极小值的简单公式更新消息。在任何时间点，每条消息的大小都反映了一个数据点选择另一个数据点作为其示例的当前亲缘关系，因此我们称我们的方法为“亲缘传播”。{@fig:消息传播流程}说明了集群是如何在消息传递过程中逐渐出现的。

![消息传播流程](https://img.imgdb.cn/item/602933ebd2a061fec7fc25c4.jpg){#fig:消息传播流程}

AP算法将数据点之间的实值相似性集合作为输入，其中相似性$s(i,k)$表示具有第$k$个数据点适合作为数据点$i$的聚类中心的程度。当目标是最小化平方误差时，每个相似性被设置为负平方误差（欧氏距离）：对于点$x_i$和点$x_k$，$s(i,k)=-||x_i-x_k||^2$。实际上，这里描述的方法可以在优化准则更一般的情况下应用。稍后，我们将描述一些任务，在这些任务中，成对的图像、成对的微阵列测量、成对的英语句子和成对的城市会产生相似性。当样本相关概率模型可用时，$s(i,k)$可以设置为数据点$i$和聚类中心点$j$的对数似然。在适当的时候，可以手工设置相似性。

与要求预先指定簇的数目不同，AP算法为每个数据点$k$取实数$s(k,k)$作为输入，使得$s(k,k)$的值较大的数据点更有可能被选择作为聚类中心。这些值被称为“偏好值（preferences）”。已识别样本的数量（集群的数量）受输入偏好值的影响，但也会从消息传递过程中出现。如果先验地，所有数据点都同样适合作为聚类中心，则应将偏好值设置为一个公共值（该值可以改变以产生不同数量的簇），**公共值可以是输入相似性的中位数（导致中等数量的聚类）或其最小值（导致少量聚类）**。

数据点之间有两种类型的消息交换，每种都考虑到不同类型的竞争。消息可以在任何阶段进行组合，以确定哪些点是聚类中心，以及其他点属于哪个中心。从数据点$i$发送到候选聚类中心点$k$的“责任（responsibility）”$r(i,k)$反映了考虑到点$i$的其他潜在聚类中心（如下图所示）的情况下，关于点$k$如何适合用作点$i$的聚类中心的累积证据。

![考虑其他中心的情况下，发送责任的情况](https://img.imgdb.cn/item/602962cfd2a061fec722d46a.jpg)

从候选样本点$k$发送到点$i$的“可用性（availability”）”$a(i,k)$反应了点$i$选择点$k$作为其聚类中心适当性的累积证据，同时考虑到其他点对点k应该是一个聚类中心的支持（如下图所示）。

![发送可用性信息](https://img.imgdb.cn/item/60296428d2a061fec7236e7e.jpg)

$r(i,k)$和$a(i,k)$可以看作对数概率比。首先，可用性被初始化为零：$a(i,k)=0$。然后，使用下式计算责任：

$$
r(i,k) \gets s(i,k)-\max_{k' \text{s.t.} k' \ne k}\{a(i,k')+s(i,k')\}
$$

在第一次迭代中，由于可用性为零，所以$r(i,k)$被设置为点$i$和作为其聚类中心的点$k$之间的输入相似度，减去点$i$和其他候选聚类中心之间的最大相似度。这种竞争性的更新是数据驱动的，并且没有考虑到有多少其他点支持每个候选聚类中心。

在以后的迭代中，当一些点被有效地分配给其他聚类中心时，它们的可用性将降到零以下，如下面的更新规则所规定的那样。这些负可用性将降低上述规则中某些输入相似性$s(i,k')$的有效值，从而将相应的候选样本从竞争中移除。对于$k=i$，责任$r(k,k)$被设置为输入偏好值，即选择点$k$作为聚类中心$s(k,k)$，减去点$i$和所有其他候选聚类中心之间的最大相似性。这种“自我责任感”反映了积累的证据，证明$k$点是一个聚类中心，这是基于它的输入偏好，而这种偏好是如何不适合分配给另一个聚类中心的。

尽管上面的责任更新允许所有候选示例竞争数据点的所有权，但是下面的可用性更新从数据点收集关于每个候选示例是否会成为一个好示例的证据：

$$
a(i,k) \gets \min \Big\{0, r(k,k) + \sum_{i' \text{s.t.} i' \notin \{i,k\}} \max \{0, r(i',k)\}\Big\}
$$

可用性$a(i,k)$被设置为自我责任$r(k,k)$加上候选聚类中心$k$从其他点接收的正责任的总和。只添加了传入责任的积极部分，因为一个好的聚类中心只需要很好地解释一些数据点（积极责任），而不管它对其他数据点（消极责任）的解释有多差。如果自我责任$r(k,k)$为负（表示k点目前更适合作为属于另一个聚类中心而不是作为聚类中心本身），那么如果一些其他点对k点作为其聚类中心具有正责任，则k点作为聚类中心的可用性可以增加。

为了限制强传入正责任的影响，对总和设置阈值，使其不能超过零。“自可用性”$a(k,k)$的更新方式不同：

$$
a(k,k) \gets \sum_{i' \text{s.t.} i' \ne k} \max \{0,r(i',k)\}
$$

该消息反映了点$k$是聚类中心的累积证据，这是基于其他点发送给候选聚类中心$k$的积极责任。

上述更新规则只需要简单的、易于实现的局部计算，并且消息只需要在具有已知相似性的点对之间交换。在AP算法运行过程中的任何时候，可用性和责任都可以结合起来识别聚类中心。对于点$i$，使$a(i,k)+r(i,k)$最大化的$k$的值，如果$k=i$，则将点$i$标识为聚类中心，或者标识作为点i的聚类中心的数据点。消息传递过程的终止有两种情况：一是在消息的变化降到阈值以下的固定次数迭代后终止，或是当一定数量的迭代之后，局部决策保持不变后终止。在更新消息时，重要的是要对消息进行阻尼，以避免在某些情况下出现数值振荡。

每个消息被设置为上一次迭代的值的$\lambda$倍加$1-\lambda$倍其规定的更新值，其中阻尼系数$\lambda$在0和1之间。在我们所有的实验（3）中，我们使用了默认的阻尼因子$\lambda=0.5$，AP算法的每次迭代包括（1）更新给定可用性的所有责任，（2）更新给定责任的所有可用性，以及（3）结合可用性和责任来监视聚类中心的决策，并且当这些决策在10次迭代中没有改变时终止算法。

{@fig:消息传播流程}显示了应用于25个二维数据点的AP算法变化情况，使用负平方误差作为相似度。AP算法的一个优点是不需要预先指定聚类的数量。相反，消息传播方法会产生适当数量的聚类中心，并取决于输入的聚类中心偏好。这使得自动模型选择成为可能，基于每个点作为聚类中心的优先程度的预先说明。下图显示了偏好输入值对集群数量的影响。这个关系与精确地最小化平方误差得到的关系几乎相同。

![偏好值对聚类数量的影响](https://img.imgdb.cn/item/602a289f3ffa7d37b34c76f4.jpg)